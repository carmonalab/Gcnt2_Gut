---
title: "Standardized Processing of scRNA-seq datasets"
author: M. Andreatta <massimo.andreatta at unil.ch>, S. Carmona <santiago.carmona
  at unil.ch>, C. Halter <christian.halter at unil.ch>, J. Garnica <josep.garnicacaparros
  at unil.ch>
---

## IMPORTANT!

**When the processing is finished, please make an entry to the [Standardized SingleCell Datasets](https://docs.google.com/spreadsheets/d/1THNE4TSbL6pa6ulCA9xsX1L7fzUCgyHpK-mgEOaUCko/edit?usp=drive_link) by filling this [form](https://forms.gle/drtCUXZyvTQYU9ih8).**

------------------------------------------------------------------------

Dataset name: Author_Year_PBMID_cohortID (eg. ZhangY_2022_34653365)

```{r dataset_name}
ds_name <- "SalasA_2023_GSE214695"
```

Meta-data timestamp: 11/30/2022 17:37:18 (to create a new entry, use <https://forms.gle/YB2w23a28DEcazeE7>) \*\*\*

Set root directory for processing

```{r set_dir}
# Set path to the directory were
# Set path to the directory were to get input and output
home.path <- file.path("/Users/aleksandarmihaylov/Documents/Carmona Lab/Gcnt2_Gut", ds_name)

knitr::opts_chunk$set(echo = T, warning = F,include=T, message=F)
```

**CHECK**: Make sure the input data and metadata are available in our repository.

If not already in the shared Dropbox folder [Standardized_SingleCell_Datasets](https://www.dropbox.com/scl/fo/uv9er8tqd23vngyzjgqd6/h?rlkey=onviske2cxev8t61ewt1hjwmq&dl=0), create a new folder for this particular dataset and download the publicly available data, then **store it in "\~/Dropbox/CSI/Standardized_SingleCell_Datasets/*your_study*/data/"**. Here we offer tools to download data directly from GEO (package `GEOquery`) and Zenodo (package `Zen4R`).

# Prepare packages and environtment

```{r load_packages_functions, message=FALSE}
# restore packages versions with renv.lock file from github repository
renv::activate()
renv::restore()

# load packages
pckgs <- c("tidyverse", "Seurat", "UCell", "scGate",
           "SingleCellExperiment","Matrix", "patchwork",
           "data.table", "STACAS", "SignatuR")
for(package in pckgs){
  library(package, character.only = T)
}

# load custom functions
source("Rutils/functions.R")

options(timeout=4000) # increase time out for downloading
```

Also, increase memory parameters to allocate large vectors, otherwise R might crash

```{bash create_Renviron}
#include vector max size
max_size=850Gb

# create .Renviron file if not present
if ! [ -a ".Renviron" ]
then
  touch .Renviron
  echo R_MAX_VSIZE=$max_size > .Renviron
  echo New .Renviron file created!
else
  echo .Renviron already present!
  echo Check size of the allowed vector:
  cat .Renviron
fi
```

# Set parameters

Dataset ID should have 3 letters from Author (Aaa) followed by additional uniquifying letter (A). If multiple cohort, followed by 1 letter from cohort ID separated by dot (e.g. AndA.H; AndB.M; And.C, etc.)

```{r define_parameters}
# Assign a short id for this data source
ID <- "SaaA"

# Assign species of the data
species <- "human"

#set seed
my_seed <- 321
set.seed(my_seed)

# max number of cells per sample (if higher, they will downsampled)
# make sure to set seed for this step
ds <- 1000

# Optional: min number of cells per sample, samples with lower number will be discarded
min.cells <- 200 
```

# Set paths

Declare the paths in your directory or Dropbox

```{r}
# Create directory to store input, output and plots
dir.create(home.path)

# Create directories for input, output and plots
input_data_path_root <- file.path(home.path, "data")
dir.create(file.path(input_data_path_root))
output_data_path <- file.path(home.path, "output")
dir.create(file.path(output_data_path))
output_plots_path <- file.path(home.path,"plots")
dir.create(file.path(output_plots_path))
```

# Download data

If not done before, download data eg from GEO or Zenodo.

If not already in the shared Dropbox folder [Standardized_SingleCell_Datasets](https://www.dropbox.com/scl/fo/uv9er8tqd23vngyzjgqd6/h?rlkey=onviske2cxev8t61ewt1hjwmq&dl=0), create a new folder for this particular dataset and download the publicly available data, then **store it in "\~/Dropbox/CSI/Standardized_SingleCell_Datasets/*your_study*/data/"**. Here we offer tools to download data directly from GEO (package `GEOquery`) and Zenodo (package `Zen4R`).

-   GEO

```{r download_GEO}
# Use "curl" for better download informations
options(download.file.method.GEOquery = "curl")

require(GEOquery)
# Set the GEO accession of the data
geo_acc <- 'GSE214695'
if(length(list.files(file.path(input_data_path_root,geo_acc)))==0){
  gse <- getGEO(geo_acc)
  getGEOSuppFiles(geo_acc, baseDir = input_data_path_root)
}

# untar files if needed
tar.files <- list.files(file.path(input_data_path_root,geo_acc),
                        "[.]tar", full.names = T)

# also set the directory for extraction
lapply(tar.files, function(f){
 untar(f, exdir=file.path(input_data_path_root,geo_acc)) 
})
```

-   Zenodo

```{r download_Zenodo, eval=F}
# require(zen4R)
# 
# if(length(list.files(path_input, "Zenodo"))==0){
#    zenodo.doi <- "10.5281/zenodo.5461803"
#    zenodo.dir <- paste0(input_data_path_root, "tar_Zenodo_Zheng")
#    dir.create(zenodo.dir)
#    download_zenodo(doi=zenodo.doi,
#                    path = zenodo.dir
#                  )
# # untar expression datasets and metadata
#   tar.zenodo.files <- list.files(zenodo.dir,
#                                 "tar",
#                                 full.names = T) %>% 
#                       # apply filter to files needed
#                       grep("expression|meta",., value = T, ignore.case = T)
#   lapply(tar.zenodo.files, untar)
# }
```

# Load Data

Depending on the data format at GEO or Zenodo, use different tools to load the datasets into the environment.

Matrices

```{r load_mtx}
fpath <- file.path(input_data_path_root, geo_acc)
data_matrices <- list()
files <- list.files(path = fpath, pattern = "matrix", full.names = TRUE)

for(file in files){
  prefix <- substr(basename(file), 1, 16)
  data_matrix <- Seurat::ReadMtx(mtx = sprintf("%s/%smatrix.mtx.gz", fpath, prefix),
                 cells = sprintf("%s/%sbarcodes.tsv.gz", fpath, prefix),
                 features = sprintf("%s/%sfeatures.tsv.gz", fpath, prefix),
                 cell.column = 1, feature.column = 1)
  
  data_matrices[[prefix]] <- data_matrix
}
```

RDS files

```{r load_rds, eval=F}
# list.rds <- list.files(input_data_path_root, "[.]rds$", full.names = T)
# list.seurat <- lapply(list.rds, readRDS) 
```

**CHECK**:

1.  Assess available assays: Are raw counts available or only pre-normalized (eg log2TMP); if pre-normalized, specify how was the normalization performed!

2.  Make sure data matrix has genes as rows and cells as columns

3.  Include, adapt and standarize cell metadata

4.  Modify cell identifiers (`orig.ident`)

5.  Standardize gene symbols

6.  Add features/genes metadata

## 1. Assess available assays

Asses whether raw counts are available or only pre-normalized (eg log2TMP), if pre-normalized, specify how was the normalization performed at the entry form (`Expression data type`). If some datasets not include raw counts consider discarding them, or if normalization approach is known, de-normalize and normalize data on all datasets. *Data input format**: e.g. pre-normalized, "by total counts, as described in <https://doi.org/10.1016/j.cell.2015.04.044>"***

## 2. Make sure data matrix has genes as rows and cells as columns

```{r check_mtx}
dim(data_matrix)
data_matrix[1:10,1:10]
head(colnames(data_matrix))
```

## 3. Include, adapt and standarize cell metadata

Generate a metadata dataframe including the following variables for each cell in the dataset. If some are not present include NA. If needed adapt metadata (factorize...).

+----------------------------+------------------------------------+
| Variable                   | Example                            |
+============================+====================================+
| Original_cell_names        | AAACCTGAGGTTACCT.Pre_P007_b        |
+----------------------------+------------------------------------+
| Barcode                    | AAACCTGAGGTTACCT                   |
+----------------------------+------------------------------------+
| Study                      | Author_Year_PBMID_cohortID         |
|                            |                                    |
|                            | (e.g. ZhangY_2022_34653365)        |
+----------------------------+------------------------------------+
| Sample                     | Pre_P007_b                         |
+----------------------------+------------------------------------+
| Treatment                  | Pre                                |
+----------------------------+------------------------------------+
| Individual                 | P007                               |
+----------------------------+------------------------------------+
| Tissue                     | blood, tumor, adjacent, LN, other  |
+----------------------------+------------------------------------+
| OriginalAnnotationLevel{n} | CD4T                               |
+----------------------------+------------------------------------+

```{r adapt_meta}
# Explore data and modifiy this code accordinly to fill the metadata slots
cell_names <- colnames(data_matrix)
cell_names.split <- strsplit(cell_names,"\\.")
meta <- list()
meta[["Original_cell_names"]] <- cell_names
meta[["Barcode"]] <- sapply(cell_names.split,function(x) x[[1]])
cell_names.split.2 <- sapply(cell_names.split,function(x) x[[2]])
meta[["Sample"]] <- cell_names.split.2
cell_names.split.2.split <- strsplit(cell_names.split.2,"\\_")
meta[["Treatment"]] <- sapply(cell_names.split.2.split,function(x) x[[1]])
meta[["Individual"]] <- sapply(cell_names.split.2.split,function(x) x[[2]])
meta[["Tissue"]] <- sapply(cell_names.split.2.split,function(x) x[[3]])

sapply(meta,head)
meta <- as.data.frame(meta)
```

## 4. Modify cell identifiers (`orig.ident`)

To make cell ids compatible with other datasets, append the study ID at the beginning of the original cell name. If available, also add other metadata elements such as Individual, tissue or treatment.

```{r modify_cellID}
#fields in prefix are separated by dots
prefix <- paste(ID, meta$Individual, meta$Tissue, meta$Treatment,sep=".")

# underscore delimits end of prefix
cell_ids <- paste(prefix, meta$Barcode, sep = '_') 
colnames(data_matrix)<- cell_ids
data_matrix[1:10,1:2]
```

Add new cells ids to metadata

```{r add_ID}
rownames(meta) <- cell_ids
head(meta)
```

## Create Seurat object (custom)

```{r Create_Seurat}
data_seurat <- CreateSeuratObject(counts=data_matrix,
                                  project=ds_name,
                                  meta.data = meta,
                                  assay="RNA",
                                  min.cells = 0,
                                  min.features = 0)
rm(data_matrix,meta,cell_ids)
# free up rstudio memory
gc() 
```

## 5. Standardize gene symbols

Map gene ids with our reference gene symbols using `STACAS::StandardizeGeneSymbols()`. Load EnsemblGenes105_Hsa_GRCh38.p13 and EnsemblGenes105_Mmu_GRCm39 retrieved at 14.02.2022 from [aux](https://github.com/carmonalab/scRNAseq_data_processing/master/aux), or already in you local directory if you cloned the repository.

```{r load_geneRef}
# load gene symbols dataset
if (species == "mouse") {
   geneRef_file <- "aux/EnsemblGenes105_Mmu_GRCm39.txt.gz"
} else if (species == "human") {
   geneRef_file <- "aux/EnsemblGenes105_Hsa_GRCh38.p13.txt.gz"
}
geneRef <- fread(geneRef_file)
```

```{r Standar_gene_Symbol}
# Standarize gene symbols using STACAS
data_seurat <- STACAS::StandardizeGeneSymbols(data_seurat, geneRef, assay = "RNA", slots = "counts")

# adapt metafeatures
# there incompatibilites with newer version of STACAS and Seurat v5
seu[["RNA"]]@meta.features <- data.frame(row.names = rownames(seu))
```

CHECK slots TODO If data pre-normalized, apply inverse of NormalizeData() into "counts" slot. Then we can run NormalizeData() routinely

```{r}
head(data_seurat@meta.data)
```

### Clean cell metadata (custom)

CHECK: cell metadata fields: Sample, Individual, Tissue c("blood","tumor","adjacent","LN","other"), Study, OriginalAnnotationLevel1, OriginalAnnotationLevel2, OriginalAnnotationLevel3... Factorize or change labels if needed.

```{r clean_metadata}
data_seurat$orig.ident <- cell_ids
data_seurat$Sample <- factor(data_seurat$Sample)
data_seurat$Individual <- factor(data_seurat$Individual)
data_seurat$Tissue <- factor(data_seurat$Tissue)
data_seurat$Tissue <- recode(data_seurat$Tissue, b = "blood", t = "tumor")
#data_seurat$OriginalAnnotationLevel1 <- 
#data_seurat$OriginalAnnotationLevel2 <- 
#data_seurat$OriginalAnnotationLevel3 <- 
head(data_seurat)
```

## 6. Add features/genes metadata

```{r add_gene_metadata}
# Remove duplicates from Gene symbols reference
features_meta_data <- geneRef[!duplicated(geneRef$`Gene name`),]
# Convert to dataframe
setDF(features_meta_data)

rownames(features_meta_data) <- features_meta_data$`Gene name`
# in Seurat, underscores ('_'), are replaced with dashes ('-')
# in gene names; 5S_rRNA; but these just a few
rownames(features_meta_data) <- gsub("_","-",rownames(features_meta_data)) 
features_meta_data <- features_meta_data[rownames(data_seurat),]

if ( all.equal(rownames(features_meta_data),
               as.character(rownames(data_seurat))) ) {
  data_seurat[["RNA"]] <- AddMetaData(data_seurat[["RNA"]],
                                      metadata = features_meta_data)
  rm(geneRef,features_meta_data)
}
```

## 7. Load and store patient metadata

Get metadata files from GEO, Zenodo or supplementary material from original publication.

We have expanded the Seurat datastructure to include "batch.metadata" in @misc

Standardize per-sample/patient attributes when available:

-   `ID`: It will allow connect per-patient metadata with main database.
-   `Patient.ID`
-   `Sample` (it may be the same as `Patient.ID` if only one sample per patient)
-   `Disease`: including cancer type or condition
-   `Tissue`
-   `Treatment`: if applicable
-   `Enrichment`: unbiased, CD45+...
-   `N_cells_whole`: integer
-   `N_cells_light`: integer
-   `Technology`: 10X, Smart-seq2, MARS-seq...
-   `Age`
-   `Sex`
-   `...`

```{r load_batch_metadata}
# Path to patient metadata
fpath <- "~/Dropbox/CSI/Standardized_SingleCell_Datasets/ZhangY_2022_34653365/data/"
individual_metadata <- read.csv(sprintf("%s/samples_metadata.csv",fpath))
rownames(individual_metadata) <- individual_metadata$Patient.ID

# check that patient metadata contain only the patients included in the sc object
individual_metadata <- individual_metadata[individual_metadata$Patient.ID %in%
                                          unique(data_seurat@meta.data$Individual),]
individual_metadata <- individual_metadata[order(individual_metadata$Patient.ID),]

# Expand Seurat data structure to add `batch.metadata` in `@misc`.
data_seurat@misc$batch.metadata <- list()
data_seurat@misc$batch.metadata$Individual <- individual_metadata
head(data_seurat@misc$batch.metadata)
```

CHECK are data pre-normalized? decide whether to Normalize

```{r norm_Data}
data_seurat <- NormalizeData(data_seurat) 
```

# Quality control measurement and filtering

## 1. Ribosomal and mitochondrial content, and sequencing complexity

Use `SignatuR` package, including ribosomal and mitochondrial gene sets, to compute their relative content. Also, compute the sequencing complexity by computing the log10 ratio of genes detected per UMI.

```{r define_qc_metrics}
#Get mitochondrial and ribosomal signatures
ribo.genes <- GetSignature(SignatuR$Hs$Compartments$Ribo)$Ribo
mito.genes <- GetSignature(SignatuR$Hs$Compartments$Mito)$Mito

# Compute ribosomal and mitochondrial content and add to Seurat object metadata
data_seurat <- AddMetaData(data_seurat, metadata = PercentageFeatureSet(data_seurat, features = ribo.genes[ribo.genes %in% rownames(data_seurat)]), col.name = "percent.ribo")
data_seurat <- AddMetaData(data_seurat, metadata = PercentageFeatureSet(data_seurat, features = mito.genes[mito.genes %in% rownames(data_seurat)]), col.name = "percent.mito")

# Compute the ratio of number of genes/features and number of counts/UMIs
data_seurat$log10GenesPerUmi <- log10(data_seurat$nFeature_RNA) / 
                                log10(data_seurat$nCount_RNA)
```

## 2. Evaluate QC metrics and filter dataset

QC-based metric is mostly done manually by inspecting the distribution of the QC metrics. QC metrics can largely change between samples, cell types included (heterogeneity), sequencing technology, and batch. Take into account that number of reads (`nCount`) are only informative if raw counts are available, otherwise they cannot be used of QC filtering.

Here are shown some guidelines for QC-based filtering:

\|--------------------------------------\|---------------------------------------------------------------------\| \| QC metric \| Guidelines for filtering \| \|--------------------------------------\|---------------------------------------------------------------------\| \| Ribosomal content \| \> 0.5% & \< 60% \| \| Mitochondrial content \| \< 10-20% \| \| Number of genes/features (nFeatures) \| \>400 and custom upper limit based on your data \| \| Number of counts/UMI (nCount) \| \>800 and custom and custom upper limit based on your data \| \| Ratio Features/Counts \| \> 0.6 \| \| Special genes \| Custom: Consider remove some of these genes for downstream analysis \| \| Special genes \| E.g. MALAT1 \| \|--------------------------------------\|---------------------------------------------------------------------\|

For MALAT1 as a QC criterion, see: <https://www.biorxiv.org/content/10.1101/2024.04.18.590104v1>

### How many cells per sample?

```{r}
sample.size.pre <- sort(table(data_seurat$Sample))
sample.size.pre
barplot(sort(sample.size.pre), las=2)
```

### CHECK: distributions across samples

```{r qc_plots0, fig.height= 10}
Idents(data_seurat) <- "Sample"
VlnPlot(data_seurat,
        features = c("nFeature_RNA", "nCount_RNA",
                     "percent.ribo","percent.mito",
                     "PTPRC","MALAT1"),
        ncol = 3, pt.size=0)
```

### Custom thresholds

Review after assessing the plots!

```{r set_cutoffs}
cutoffs <- list()
cutoffs[["percent.ribo"]] <- c(min=0.5,max=60)
cutoffs[["percent.mito"]] <- c(min=0,max=20)
cutoffs[["nFeature_RNA"]] <- c(min=400,max=6000) 
cutoffs[["nCount_RNA"]] <- c(min=800,max=40000) # raw counts present??
cutoffs[["log10GenesPerUmi"]] <- 0.6
cutoffs[["MALAT1"]] <- 2
print(cutoffs)
```

### Filter out outliers & low quality cells (custom)

```{r qc_plots}
Idents(data_seurat) <- "Sample"
VlnPlot(data_seurat,
        features = c("nFeature_RNA", "nCount_RNA",
                     "percent.ribo","percent.mito",
                     "MALAT1"),
        ncol = 2, pt.size=0)

# When using qc_plot cutoffs should be a list with the same names for 
# QC metrics as in the metadata
qclist <- lapply(names(cutoffs), function(c){  # names of QC metrics to evaluate
  qc_plot(data_seurat@meta.data, var=c, cutoffs = cutoffs)
})

# Join all plots into a single one
wrap_plots(qclist)

```

### Standard check

```{r probs}
probs <- c(0.001, 0.005, 0.01, 0.02,
           0.98, 0.99, 0.995, 0.999)
for (va in names(cutoffs)) {
  cat(va, "\n")
  if (va %in% names(data_seurat@meta.data)) {
    print(quantile(data_seurat@meta.data[[va]],
                   probs = probs)
    )
  } else {
    print(quantile(FetchData(data_seurat, vars = va)[[1]],
                   probs = probs))
  }
}
```

After having evaluated the QC metrics values and distribution, modify cutoffs if needed and then proceed to subset your data based on those. Also, evaluate how many cells are being removed based on your cutoffs.

```{r subset_seurat, fig.height= 10}
# store initial number of cells
initialCellNum <- ncol(data_seurat)
message(paste("Original number of cells:", initialCellNum))

# Perform subsetting using cutoffs list and qc metrics considered
data_seurat <- subset(data_seurat, subset = 
                        nFeature_RNA >= cutoffs[["nFeature_RNA"]]["min"] &
                        nFeature_RNA < cutoffs[["nFeature_RNA"]]["max"] & 
                        # raw counts present??
                        nCount_RNA   >= cutoffs[["nCount_RNA"]]["min"]   & 
                        nCount_RNA   < cutoffs[["nCount_RNA"]]["max"]   &  
                        percent.ribo >= cutoffs[["percent.ribo"]]["min"] & 
                        percent.ribo < cutoffs[["percent.ribo"]]["max"] &
                        percent.mito >= cutoffs[["percent.mito"]]["min"] &
                        percent.mito < cutoffs[["percent.mito"]]["max"] &
                        log10GenesPerUmi > cutoffs[["log10GenesPerUmi"]] &
                        MALAT1 > cutoffs[["MALAT1"]]
                      )

# Print and evaluate the cell drop out after filtering
l <- ncol(data_seurat)
message(sprintf("Number of cells after QC: %i (%.2f %% of input)", l, 100*l/initialCellNum))
```

# Downsample, process dataset and make diagnostic plots

At this point we should only have in our datasets high quality cells. We will remove samples with very few cells and downsample large ones, in order to have a similar contribution from all patients and samples. Downsampling large samples also speeds up downstream computations.

We will save the datasets with all high-quality cells (whole) and datasets without small samples and downsampling large ones (light).

```{r remove_small_samples}
# Viasualize cell number cutoffs
cells.perSample <- table(data_seurat$Sample)
barplot(sort(cells.perSample))
abline(h=min.cells)
abline(h=ds)


# Remove small samples
tab <- table(data_seurat$Sample)
keep <- names(tab)[tab > min.cells]
data_seurat.ds <- subset(data_seurat, patient_id %in% keep)

# Print number of samples removed
cat(length(tab[tab <= min.cells]), "samples removed out of a total of ", length(tab) )

# Print and evaluate the cell drop out after this step
l <- ncol(data_seurat.ds)
message(sprintf("Number of cells after QC: %i (%.2f %% of input)",
                l, 100*l/initialCellNum))
```

```{r downsample}
# Downsample
Idents(data_seurat.ds) <- "Sample"
# Set seed for downsampling
set.seed(my_seed)
data_seurat.ds <- subset(data_seurat.ds, downsample = ds)

# Explore the number of cells per sample
table(data_seurat.ds$Sample)

# Print and evaluate the cell drop out after this step
l <- ncol(data_seurat.ds)
message(sprintf("Number of cells after QC: %i (%.2f %% of input)",
                l, 100*l/initialCellNum))
```

### How many cells per sample after QC?

```{r, fig.height = 8, fig.width = 20}
barplot(sort(sample.size.pre), las=2)

sample.size.post <- table(data_seurat$Sample)[names(sample.size.pre)]
sample.size.post
barplot((sample.size.post), las=2)
barplot(sort(sample.size.post), las=2)

sample.size.filterRatio <- round((sample.size.pre - sample.size.post)/sample.size.pre*100,2)
sample.size.filterRatio
barplot(sample.size.filterRatio[names(sort(sample.size.post))], las=2)
```

# Export standardized datasets

```{r}
saveRDS(data_seurat,file.path(output_data_path,paste0(ds_name,"whole.rds")))
saveRDS(data_seurat,file.path(output_data_path,paste0(ds_name,"light.rds")))
```

# Export patient/sample metadata

```{r}
write.csv(individual_metadata,
          file.path(output_data_path,paste0(ds_name,"individual_metadata.csv")))
```

# Consider saving as H5 (<https://github.com/mojaveazure/seurat-disk>) for interoperability with Bioconductor and Python; eg SaveH5Seurat()

## Save H5 file

SaveH5Seurat save the whole seurat object, including metadata. For tools such as CellBender we require only the matrix count to be saved in a .h5 file, not a .h5Seurat.

```{r}
write_dgCMatrix_h5(GetAssayData(object = merged.seurat, slot = "counts"),
                    cols_are = "sample_names",
                    h5_target = paste0(filename, ".h5"),
                    ref_name = ds_name)
```

**IMPORTANT** CHECK: after running this workflow (on a fresh session); commit/push final version and record in the Google form (<https://forms.gle/drtCUXZyvTQYU9ih8>) the Github SHA/commit ref (eg 5815f1be791ecef1e0e8dffed12ef3879074a412)
